{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead40cfa-5393-434f-b7d1-03973517373e",
   "metadata": {},
   "source": [
    "# OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a57115-e748-49d6-8a4f-91c3152413cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "def collect_openalex_data(query, start_year=2019, end_year=2024, max_results=2000, email=None):\n",
    "    base_url = \"https://api.openalex.org/works\"\n",
    "    \n",
    "    headers = {}\n",
    "    if email:\n",
    "        headers['User-Agent'] = f'Python-Research-Script ({email})'\n",
    "    \n",
    "    filters = [\n",
    "        f\"publication_year:{start_year}-{end_year}\",\n",
    "        \"type:article\",\n",
    "        \"is_paratext:false\"\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        'search': query,\n",
    "        'filter': ','.join(filters),\n",
    "        'sort': 'cited_by_count:desc',\n",
    "        'per_page': 100,\n",
    "        'cursor': '*'\n",
    "    }\n",
    "    \n",
    "    all_works = []\n",
    "    total_collected = 0\n",
    "    \n",
    "    print(f\"Collecte de données depuis OpenAlex pour la requête: {query}\")\n",
    "\n",
    "    with tqdm(total=max_results) as pbar:\n",
    "        while total_collected < max_results:\n",
    "            try:\n",
    "                response = requests.get(base_url, params=params, headers=headers)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                data = response.json()\n",
    "                works = data.get('results', [])\n",
    "                \n",
    "                if not works:\n",
    "                    print(\"Plus de résultats disponibles.\")\n",
    "                    break\n",
    "                \n",
    "                for work in works:\n",
    "                    work_data = extract_work_data(work)\n",
    "                    all_works.append(work_data)\n",
    "                    total_collected += 1\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    if total_collected >= max_results:\n",
    "                        break\n",
    "                        \n",
    "                next_cursor = data.get('meta', {}).get('next_cursor')\n",
    "                if not next_cursor:\n",
    "                    print(\"Fin des résultats (pas de curseur suivant).\")\n",
    "                    break\n",
    "                    \n",
    "                params['cursor'] = next_cursor\n",
    "                \n",
    "                time.sleep(0.3)\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Erreur lors de la requête à l'API: {e}\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "    \n",
    "    df = pd.DataFrame(all_works)\n",
    "    \n",
    "    print(f\"Collecte terminée. {len(df)} articles récupérés depuis OpenAlex.\")\n",
    "    return df\n",
    "\n",
    "def extract_work_data(work):\n",
    "    authors = []\n",
    "    author_countries = []\n",
    "    author_institutions = []\n",
    "    \n",
    "    for author in work.get('authorships', []):\n",
    "        author_name = author.get('author', {}).get('display_name', '')\n",
    "        if author_name:\n",
    "            authors.append(author_name)\n",
    "            \n",
    "        for institution in author.get('institutions', []):\n",
    "            country = institution.get('country_code', '')\n",
    "            if country:\n",
    "                author_countries.append(country)\n",
    "            \n",
    "            institution_name = institution.get('display_name', '')\n",
    "            if institution_name:\n",
    "                author_institutions.append(institution_name)\n",
    "    \n",
    "    concepts = []\n",
    "    concept_scores = []\n",
    "    for concept in work.get('concepts', []):\n",
    "        concept_name = concept.get('display_name', '')\n",
    "        if concept_name:\n",
    "            concepts.append(concept_name)\n",
    "            concept_scores.append(concept.get('score', 0))\n",
    "    \n",
    "    primary_location = work.get('primary_location') or {}\n",
    "    source = primary_location.get('source') or {}\n",
    "    abstract = \"\"\n",
    "    abstract_index = work.get('abstract_inverted_index', None)\n",
    "    if abstract_index:\n",
    "        index_to_word = []\n",
    "        for word, positions in abstract_index.items():\n",
    "            for pos in positions:\n",
    "                index_to_word.append((pos, word))\n",
    "        sorted_words = [word for _, word in sorted(index_to_word)]\n",
    "        abstract = ' '.join(sorted_words)\n",
    "\n",
    "    work_data = {\n",
    "        'id': work.get('id', '').replace('https://openalex.org/', ''),\n",
    "        'title': work.get('title', ''),\n",
    "        'doi': work.get('doi', ''),\n",
    "        'authors': '; '.join(authors),\n",
    "        'publication_date': work.get('publication_date', ''),\n",
    "        'year': work.get('publication_year', None),\n",
    "        'open_access': work.get('open_access', {}).get('is_oa', False),\n",
    "        'cited_by_count': work.get('cited_by_count', 0),\n",
    "        'abstract': abstract,\n",
    "        'concepts': '; '.join(concepts[:5]),\n",
    "        'concept_scores': '; '.join([str(score) for score in concept_scores[:5]]),\n",
    "        'author_countries': '; '.join(set(author_countries)),\n",
    "        'author_institutions': '; '.join(set(author_institutions[:3])),\n",
    "        'referenced_works_count': len(work.get('referenced_works', [])),\n",
    "        'type': work.get('type', '')\n",
    "    }\n",
    "\n",
    "    concepts = [c.get('display_name', '') for c in work.get('concepts', []) if c.get('display_name')]\n",
    "    work_data['categories'] = ', '.join(concepts)\n",
    "\n",
    "    \n",
    "    return work_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generative_ai_query = '\"generative AI\" OR \"generative model\" OR \"diffusion model\" OR \"large language model\" OR \"LLM\" OR \"GANs\" OR \"transformer model\" OR \"stable diffusion\" OR \"text-to-image\" OR \"GPT\" OR \"DALL-E\" OR \"image generation\" OR \"text generation\"'\n",
    "    \n",
    "    YOUR_EMAIL = \"yassmine123fanid@gmail.com\"\n",
    "    \n",
    "    openalex_df = collect_openalex_data(\n",
    "        query=generative_ai_query,\n",
    "        start_year=2019,\n",
    "        end_year=2024,\n",
    "        max_results=2000,\n",
    "        email=YOUR_EMAIL\n",
    "    )\n",
    "    \n",
    "    output_file = f'data/openalex_generative_ai_data_{datetime.datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "    openalex_df.to_csv(output_file, index=False)\n",
    "    print(f\"Données sauvegardées dans {output_file}\")\n",
    "    print(\"\\nRésumé des données collectées:\")\n",
    "    print(f\"Nombre total d'articles: {len(openalex_df)}\")\n",
    "    \n",
    "    if not openalex_df.empty:\n",
    "        years_count = openalex_df['year'].value_counts().sort_index()\n",
    "        print(\"\\nDistribution par année:\")\n",
    "        for year, count in years_count.items():\n",
    "            print(f\"  {year}: {count} articles\")\n",
    "        \n",
    "        top_cited = openalex_df.nlargest(5, 'cited_by_count')\n",
    "        print(\"\\nTop 5 des articles les plus cités:\")\n",
    "        for _, row in top_cited.iterrows():\n",
    "            print(f\"  {row['title']} - Citations: {row['cited_by_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641cc724-ddb1-4724-8398-f4b6c53744da",
   "metadata": {},
   "outputs": [],
   "source": [
    "openalex_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63828870-36e3-46df-baa9-1ef40592023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openalex_df = pd.read_csv(\"data/openalex_generative_ai_data_20250516.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
