{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cccd75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def collect_arxiv_data(search_query, max_results=1000, start_year=2019, end_year=2024):\n",
    "\n",
    "    print(f\"Collecte de {max_results} articles maximum depuis arXiv avec la requête: {search_query}\")\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query=search_query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "        sort_order=arxiv.SortOrder.Descending\n",
    "    )\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    for result in tqdm(search.results(), total=max_results):\n",
    "        pub_date = result.published\n",
    "        pub_year = pub_date.year\n",
    "        \n",
    "        if pub_year < start_year or pub_year > end_year:\n",
    "            continue\n",
    "        \n",
    "        article = {\n",
    "            'id': result.entry_id.split('/')[-1],\n",
    "            'title': result.title,\n",
    "            'authors': ', '.join([author.name for author in result.authors]),\n",
    "            'abstract': result.summary.replace('\\n', ' '),\n",
    "            'categories': ', '.join(result.categories),\n",
    "            'primary_category': result.primary_category,\n",
    "            'published_date': result.published.strftime('%Y-%m-%d'),\n",
    "            'year': result.published.year,\n",
    "            'month': result.published.month,\n",
    "            'comment': result.comment if hasattr(result, 'comment') else None,\n",
    "            'doi': result.doi if hasattr(result, 'doi') else None\n",
    "        }\n",
    "        \n",
    "        articles.append(article)\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    df = pd.DataFrame(articles)\n",
    "    \n",
    "    print(f\"Collecte terminée. {len(df)} articles récupérés.\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generative_ai_query = 'ti:\"generative AI\" OR ti:\"generative model\" OR ti:\"generative adversarial\" OR ' \\\n",
    "                          'ti:\"diffusion model\" OR ti:\"large language model\" OR ti:\"text-to-image\" OR ti:\"text to image\" OR ' \\\n",
    "                          'ti:\"image generation\" OR ti:\"text generation\" OR ti:\"stable diffusion\" OR ' \\\n",
    "                          'ti:\"GPT\" OR ti:\"LLM\" OR ti:\"generative pre-trained\" OR ' \\\n",
    "                          'abs:\"generative AI\" AND (cat:cs.AI OR cat:cs.CL OR cat:cs.CV OR cat:cs.LG)'\n",
    "    \n",
    "    generative_ai_df = collect_arxiv_data(\n",
    "        search_query=generative_ai_query,\n",
    "        max_results=2000,\n",
    "        start_year=2019,\n",
    "        end_year=2024\n",
    "    )\n",
    "    \n",
    "    output_file = f'data/arxiv_generative_ai_data_{datetime.datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "    generative_ai_df.to_csv(output_file, index=False)\n",
    "    print(f\"Données sauvegardées dans {output_file}\")\n",
    "    \n",
    "    print(\"\\nRésumé des données collectées:\")\n",
    "    print(f\"Nombre total d'articles: {len(generative_ai_df)}\")\n",
    "    \n",
    "    years_count = generative_ai_df['year'].value_counts().sort_index()\n",
    "    print(\"\\nDistribution par année:\")\n",
    "    for year, count in years_count.items():\n",
    "        print(f\"  {year}: {count} articles\")\n",
    "    \n",
    "    categories_count = generative_ai_df['primary_category'].value_counts().head(10)\n",
    "    print(\"\\nTop 10 des catégories principales:\")\n",
    "    for category, count in categories_count.items():\n",
    "        print(f\"  {category}: {count} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f3c7f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arxiv_df = pd.read_csv(\"data/arxiv_generative_ai_data_20250516.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dae8a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "arxiv_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b799a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "arxiv_df.dtypes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
